{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as nng\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src.simulations import SurfaceCodeSim\n",
    "from src.graph import get_batch_of_graphs\n",
    "from src.models import MWPMLoss\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialise settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 3\n",
    "code_sz = 3\n",
    "p = 1e-3\n",
    "n_shots = 1000\n",
    "sim = SurfaceCodeSim(reps, code_sz, p, n_shots, seed=1)\n",
    "n_epochs = 10\n",
    "n_batches = 1\n",
    "factor = -0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a simple network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitSyndromes(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, edges, edge_attr, detector_labels):\n",
    "\n",
    "        node_range = torch.arange(0, detector_labels.shape[0])\n",
    "        node_subset = node_range[detector_labels]\n",
    "        \n",
    "        valid_labels = torch.isin(edges, node_subset).sum(dim=0) == 2\n",
    "        return edges[:, valid_labels], edge_attr[valid_labels, :]\n",
    "\n",
    "class GATGNN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_heads=2, edge_dimensions=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gat1 = nng.GATConv(\n",
    "            5,\n",
    "            16,\n",
    "            heads=n_heads,\n",
    "            concat=False,\n",
    "            edge_dim=edge_dimensions,\n",
    "            add_self_loops=False,\n",
    "        )\n",
    "        self.gat2 = nng.GATConv(\n",
    "            16,\n",
    "            32,\n",
    "            heads=n_heads,\n",
    "            concat=False,\n",
    "            edge_dim=edge_dimensions,\n",
    "            add_self_loops=False,\n",
    "        )\n",
    "        \n",
    "        self.split_syndromes = SplitSyndromes()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, edges, edge_attr, detector_labels):\n",
    "        # edge_attr.retain_grad()\n",
    "        print(f\"{edge_attr.is_leaf=}\")\n",
    "        print(f\"{edge_attr.requires_grad=}\")\n",
    "        x, (edges, edge_attr) = self.gat1(\n",
    "            x, edges, edge_attr, return_attention_weights=True\n",
    "        )\n",
    "        edge_attr.retain_grad()\n",
    "        print(f\"{edge_attr.is_leaf=}\")\n",
    "        print(f\"{edge_attr.requires_grad=}\")\n",
    "        x = torch.nn.functional.relu(x, inplace=True)\n",
    "        _, (edges, edge_attr) = self.gat2(\n",
    "            x, edges, edge_attr, return_attention_weights=True\n",
    "        )\n",
    "\n",
    "        edges, edge_attr = self.split_syndromes(edges, edge_attr, detector_labels)\n",
    "        edge_attr.retain_grad()\n",
    "        # print(f\"{edge_attr[:10, 1]=}\")\n",
    "        # edge_attr[:, 1] = self.sigmoid(edge_attr[:, 1])\n",
    "        # print(f\"{edge_attr[:10, 1]}\")\n",
    "        edge_attr = self.sigmoid(edge_attr)\n",
    "        edge_attr.retain_grad()\n",
    "        # print(edge_attr.requires_grad)\n",
    "        print(edge_attr.grad)\n",
    "        return edges, edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "class GNNLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, edge_attr_dim, out_channels):\n",
    "        super(GNNLayer, self).__init__(aggr='add')  # \"Add\" aggregation.\n",
    "        self.linear = nn.Linear(in_channels + edge_attr_dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "        # edge_attr has shape [E, edge_attr_dim]\n",
    "\n",
    "        # Transform node feature matrix.\n",
    "        x = self.linear(torch.cat([x, edge_attr], dim=1))\n",
    "\n",
    "        # Propagate messages.\n",
    "        return self.propagate(edge_index, x=x)\n",
    "\n",
    "    def message(self, x_j):\n",
    "        # x_j has shape [E, out_channels]\n",
    "        return x_j\n",
    "\n",
    "class GNNWithEdgeFeatures(nn.Module):\n",
    "    def __init__(self, input_dim, edge_attr_dim, hidden_dim, edge_feat_dim):\n",
    "        super(GNNWithEdgeFeatures, self).__init__()\n",
    "        self.gnn_layer = GNNLayer(input_dim, edge_attr_dim, hidden_dim)\n",
    "        self.edge_model = nn.Linear(hidden_dim, edge_feat_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        node_feats = self.gnn_layer(x, edge_index, edge_attr)\n",
    "        edge_feats = self.edge_model(node_feats)\n",
    "        return edge_feats\n",
    "\n",
    "# Example usage:\n",
    "input_dim = 32\n",
    "edge_attr_dim = 8\n",
    "hidden_dim = 64\n",
    "edge_feat_dim = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Do a training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GNNWithEdgeFeatures.forward() takes 4 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m x, edges, edge_attr, batch_labels, detector_labels \u001b[38;5;241m=\u001b[39m get_batch_of_graphs(syndromes, \u001b[38;5;241m20\u001b[39m, code_sz)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# print(edge_attr.is_leaf)\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m edges, edge_attr \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetector_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m node_range \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fun(\n\u001b[0;32m     22\u001b[0m edges,\n\u001b[0;32m     23\u001b[0m edge_attr,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m factor\n\u001b[0;32m     28\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\isakb\\miniforge3\\envs\\dml_cpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\isakb\\miniforge3\\envs\\dml_cpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: GNNWithEdgeFeatures.forward() takes 4 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "# model = GATGNN()\n",
    "model = GNNWithEdgeFeatures(input_dim, edge_attr_dim, hidden_dim, edge_feat_dim)\n",
    "model.train()\n",
    "loss_fun = MWPMLoss.apply\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# first_att = model.state_dict()[\"gat1.att_edge\"]\n",
    "# second_att = model.state_dict()[\"gat2.att_edge\"]\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = 0\n",
    "    epoch_n_graphs = 0\n",
    "    # print(first_att - model.state_dict()[\"gat1.att\"])\n",
    "    # print(second_att - model.state_dict()[\"gat2.att\"])\n",
    "    for _ in range(n_batches):\n",
    "        optim.zero_grad()\n",
    "        syndromes, flips, n_trivial = sim.generate_syndromes(n_shots)\n",
    "        x, edges, edge_attr, batch_labels, detector_labels = get_batch_of_graphs(syndromes, 20, code_sz)\n",
    "        # print(edge_attr.is_leaf)\n",
    "        edges, edge_attr = model(x, edges, edge_attr, detector_labels)\n",
    "        node_range = torch.arange(0, x.shape[0])\n",
    "        loss = loss_fun(\n",
    "        edges,\n",
    "        edge_attr,\n",
    "        batch_labels,\n",
    "        node_range,\n",
    "        np.array(flips) * 1,\n",
    "        factor\n",
    "        )\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        # print(loss.grad)\n",
    "        \n",
    "        n_graphs = syndromes.shape[0]\n",
    "        train_loss += loss.item() * n_graphs\n",
    "        epoch_n_graphs += n_graphs\n",
    "    train_loss /= epoch_n_graphs\n",
    "    \n",
    "    # print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 100 but got size 200 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, num_graphs, (num_nodes,))\n\u001b[0;32m     61\u001b[0m model \u001b[38;5;241m=\u001b[39m GNNWithEdgeFeatures(input_dim, edge_attr_dim, hidden_dim)\n\u001b[1;32m---> 62\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# Output shape: [num_edges, 2]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\isakb\\miniforge3\\envs\\dml_cpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\isakb\\miniforge3\\envs\\dml_cpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 43\u001b[0m, in \u001b[0;36mGNNWithEdgeFeatures.forward\u001b[1;34m(self, x, edge_index, edge_attr, batch)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, edge_attr, batch):\n\u001b[1;32m---> 43\u001b[0m     node_feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgnn_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     edge_feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_model(node_feats)\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m edge_feats\n",
      "File \u001b[1;32mc:\\Users\\isakb\\miniforge3\\envs\\dml_cpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\isakb\\miniforge3\\envs\\dml_cpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 19\u001b[0m, in \u001b[0;36mGNNLayer.forward\u001b[1;34m(self, x, edge_index, edge_attr, batch)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, edge_attr, batch):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# x has shape [N, in_channels]\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# edge_index has shape [2, E]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# Transform node feature matrix.\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Propagate messages.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39mx, size\u001b[38;5;241m=\u001b[39m(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)), batch\u001b[38;5;241m=\u001b[39mbatch)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 100 but got size 200 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree, scatter\n",
    "\n",
    "class GNNLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, edge_attr_dim, out_channels):\n",
    "        super(GNNLayer, self).__init__(aggr='add')  # \"Add\" aggregation.\n",
    "        self.linear = nn.Linear(in_channels + edge_attr_dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "        # edge_attr has shape [E, edge_attr_dim]\n",
    "        # batch has shape [N]\n",
    "\n",
    "        # Transform node feature matrix.\n",
    "        x = self.linear(torch.cat([x, edge_attr], dim=1))\n",
    "\n",
    "        # Propagate messages.\n",
    "        return self.propagate(edge_index, x=x, size=(x.size(0), x.size(0)), batch=batch)\n",
    "\n",
    "    def message(self, x_j):\n",
    "        # x_j has shape [E, out_channels]\n",
    "        return x_j\n",
    "\n",
    "class EdgeModel(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(EdgeModel, self).__init__()\n",
    "        self.edge_predictor = nn.Linear(in_channels, 2)  # Output dimension 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.edge_predictor(x)\n",
    "\n",
    "class GNNWithEdgeFeatures(nn.Module):\n",
    "    def __init__(self, input_dim, edge_attr_dim, hidden_dim):\n",
    "        super(GNNWithEdgeFeatures, self).__init__()\n",
    "        self.gnn_layer = GNNLayer(input_dim, edge_attr_dim, hidden_dim)\n",
    "        self.edge_model = EdgeModel(hidden_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        node_feats = self.gnn_layer(x, edge_index, edge_attr, batch)\n",
    "        edge_feats = self.edge_model(node_feats)\n",
    "        return edge_feats\n",
    "\n",
    "# Example usage:\n",
    "input_dim = 32\n",
    "edge_attr_dim = 2\n",
    "hidden_dim = 64\n",
    "\n",
    "# Create example input data\n",
    "num_nodes = 100\n",
    "num_edges = 200\n",
    "num_graphs = 5\n",
    "x = torch.randn(num_nodes, input_dim)\n",
    "edge_index = torch.randint(0, num_nodes, (2, num_edges))\n",
    "edge_attr = torch.randn(num_edges, edge_attr_dim)\n",
    "batch = torch.randint(0, num_graphs, (num_nodes,))\n",
    "\n",
    "model = GNNWithEdgeFeatures(input_dim, edge_attr_dim, hidden_dim)\n",
    "output = model(x, edge_index, edge_attr, batch)\n",
    "print(output.shape)  # Output shape: [num_edges, 2]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dml_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
